# Deckard

Deckard is a realtime AI avatar system:
- Voice conversation is handled with OpenAI Realtime + OpenAI Agents SDK.
- Persona mood and tool use are orchestrated in a FastAPI websocket server.
- Lip-sync video is generated by a self-hosted open-source model server (co-located GPU pod path supported).

## Current Status

- Active conversation orchestration uses `server/app/main.py`.
- Active lip-sync path uses `server/app/services/lipsync.py` (not the legacy D-ID runtime path).
- Optional co-located model server exists at `server/app/lipsync_server/`.
- Lightweight memory/personalization is wired into websocket sessions via `memory_key`.

## Quick Start

## 1) Backend

```bash
cd server
uv sync
cp .env.example .env.local
uv run uvicorn app.main:app --host 0.0.0.0 --port 8000
```

Required env:
- `OPENAI_API_KEY`
- Lip-sync provider:
  - `LIPSYNC_DIRECT_URL` (recommended for same-pod model server), or
  - RunPod serverless variables (`RUNPOD_API_KEY` + endpoint/run/status config)

## 2) Frontend

```bash
cd web
npm install
npm run dev
```

Optional frontend env:
- `NEXT_PUBLIC_REALTIME_WS_URL` (defaults to `ws://localhost:8000`)

## 3) Same-Pod GPU Setup (recommended for low latency)

Run two processes on the pod:
- Deckard API on `:8000`
- Lip-sync inference API on `:8001`

Then set:
- `LIPSYNC_DIRECT_URL=http://127.0.0.1:8001/generate`

## Developer Documentation

- `docs/DEVELOPER_GUIDE.md` - onboarding, local dev workflow, contribution checklist
- `docs/ARCHITECTURE.md` - runtime architecture and event flow
- `docs/RUNBOOK.md` - production/runpod operations and debugging checklist
- `server/README.md` - backend-focused setup and integration notes

## Validation Commands

```bash
cd server && uv run pytest
cd web && npm run lint
cd web && npm run build
```

## Notes

- Keep secrets in local env files only (`.env`, `.env.local`, `server/.env.local`, `web/.env.local`).
- The repo includes legacy D-ID service code for compatibility/reference, but active MVP flow should use `LipSyncService`.
